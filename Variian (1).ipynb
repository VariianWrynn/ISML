{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(train_path=\"train.csv\", test_path=\"test.csv\"):\n",
    "    \"\"\"\n",
    "    Load data from CSV files and split into training, validation, and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_path: Path to the training CSV file.\n",
    "    - test_path: Path to the testing CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    - train_data, train_labels: Training data and labels.\n",
    "    - val_data, val_labels: Validation data and labels.\n",
    "    - test_data, test_labels: Test data and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load train.csv and split\n",
    "    train_df = pd.read_csv(train_path, header=None)\n",
    "\n",
    "    train_data = train_df.iloc[:4000, 1:].values\n",
    "    train_labels = train_df.iloc[:4000, 0].values\n",
    "\n",
    "    # print(\"The first 10 labels in the training set are: \", train_labels[:10])\n",
    "    # print(\"The first 10 features in the training set are: \", train_data[:10])    \n",
    "    \n",
    "    val_data = train_df.iloc[4000:, 1:].values\n",
    "    val_labels = train_df.iloc[4000:, 0].values\n",
    "    \n",
    "    # Load test.csv\n",
    "    test_df = pd.read_csv(test_path, header=None)\n",
    "    test_data = test_df.iloc[:, 1:].values\n",
    "    test_labels = test_df.iloc[:, 0].values\n",
    "\n",
    "    test_labels = test_labels * 2 - 1\n",
    "    val_labels = val_labels * 2 - 1\n",
    "    train_labels = train_labels * 2 - 1\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "# Load data\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_and_split_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, w, b):\n",
    "    \"\"\"\n",
    "    Predict labels for given data using weight vector w and bias b.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Data matrix.\n",
    "    - w: Weight vector.\n",
    "    - b: Bias scalar.\n",
    "    \n",
    "    Returns:\n",
    "    - labels: Predicted labels.\n",
    "    \"\"\"\n",
    "    return np.sign(data @ w + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_primal(data_train, label_train, regularisation_para_C):\n",
    "    \"\"\"\n",
    "    Train a linear SVM in the primal form using cvxpy.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_train: Training data matrix of shape (N, d)\n",
    "    - label_train: Training labels vector of shape (N, )\n",
    "    - regularisation_para_C: Regularization parameter\n",
    "    \n",
    "    Returns:\n",
    "    - w: Weight vector of shape (d, )\n",
    "    - b: Bias (scalar)\n",
    "    \"\"\"\n",
    "    \n",
    "    N, d = data_train.shape\n",
    "    w = cp.Variable(d)\n",
    "    b = cp.Variable()\n",
    "    xi = cp.Variable(N)\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(0.5 * cp.norm(w,2)**2 + (regularisation_para_C/N) * cp.sum(xi))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [cp.multiply(label_train, data_train @ w + b) >= 1 - xi, xi >= 0]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return w.value, b.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix K is NOT positive semidefinite. Minimum eigenvalue: -2.726553868824963e-11\n"
     ]
    }
   ],
   "source": [
    "def is_positive_semidefinite(K):\n",
    "    \"\"\"\n",
    "    Check if matrix K is positive semidefinite.\n",
    "    \n",
    "    Parameters:\n",
    "    - K: Square matrix\n",
    "    \n",
    "    Returns:\n",
    "    - True if K is positive semidefinite, False otherwise.\n",
    "    \"\"\"\n",
    "    eigenvalues = np.linalg.eigvalsh(K)\n",
    "    return np.all(eigenvalues >= 0)\n",
    "\n",
    "# Construct the kernel (gram matrix) for the training data\n",
    "K = np.outer(train_labels, train_labels) * (train_data @ train_data.T)\n",
    "\n",
    "# Check if K is positive semidefinite\n",
    "if is_positive_semidefinite(K):\n",
    "    print(\"Matrix K is positive semidefinite.\")\n",
    "else:\n",
    "    print(\"Matrix K is NOT positive semidefinite. Minimum eigenvalue:\", np.min(np.linalg.eigvalsh(K)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    regularization_term = 1e-5\n",
    "    N, _ = data_train.shape\n",
    "    alpha = cp.Variable(N)\n",
    "    \n",
    "    # Construct the kernel (gram matrix) with regularization\n",
    "    K = np.outer(label_train, label_train) * (data_train @ data_train.T)\n",
    "    K += np.eye(N) * regularization_term\n",
    "    \n",
    "    # Explicitly compute the quadratic term for the objective using quad_form\n",
    "    quadratic_term = 0.5 * cp.quad_form(alpha, K)\n",
    "    \n",
    "    # Objective\n",
    "    objective = cp.Minimize(-1 * cp.sum(alpha) + quadratic_term)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(cp.multiply(alpha, label_train)) == 0,\n",
    "        alpha >= 0,\n",
    "        alpha <= regularisation_para_C / N\n",
    "    ]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return alpha.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict_primal(data, labels, svm_model):\n",
    "    \"\"\"\n",
    "    Predict using the primal SVM model and return accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Data matrix (N x D)\n",
    "    - labels: Ground truth labels (N,)\n",
    "    - svm_model: Trained SVM model with 'w' and 'b' as keys\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy of predictions\n",
    "    \"\"\"\n",
    "    # Extract w and b from the model\n",
    "    w = svm_model['w']\n",
    "    b = svm_model['b']\n",
    "\n",
    "    # Predict\n",
    "    preds = np.sign(np.dot(data, w) + b)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(preds == labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_svm_driver():\n",
    "    # Load data\n",
    "    train_data, train_labels, val_data, val_labels, test_data, test_labels = load_and_split_data()\n",
    "    \n",
    "    # Train SVM\n",
    "    w, b = svm_train_primal(train_data, train_labels, 100)\n",
    "\n",
    "    print(\"sum of w: \", np.sum(w))\n",
    "    print(\"b: \", b)\n",
    "    \n",
    "    # Predict on validation and test sets\n",
    "    val_preds = predict(val_data, w, b)\n",
    "    test_preds = predict(test_data, w, b)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    val_accuracy = np.mean(val_preds == val_labels)\n",
    "    test_accuracy = np.mean(test_preds == test_labels)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_svm_driver():\n",
    "        # Load the data (assuming load_and_split_data is defined)\n",
    "    train_data, train_labels, _, _, _, _ = load_and_split_data()\n",
    "\n",
    "    # # Convert labels from {0, 1} to {-1, 1}\n",
    "    # train_labels = 2 * train_labels - 1\n",
    "\n",
    "    # Train SVM in dual form\n",
    "    alpha_values = svm_train_dual(train_data, train_labels, 100)\n",
    "\n",
    "    # Compute the weight vector w\n",
    "    w = np.sum((alpha_values * train_labels)[:, None] * train_data, axis=0)\n",
    "\n",
    "    # Compute the bias b using a support vector (any example where 0 < alpha < C/N can be a support vector)\n",
    "    support_vector_indices = np.where((alpha_values > 1e-5) & (alpha_values < (100/train_data.shape[0])))[0]\n",
    "    if len(support_vector_indices) > 0:\n",
    "        sv_index = support_vector_indices[0]\n",
    "        b = train_labels[sv_index] - np.dot(w, train_data[sv_index])\n",
    "    else:\n",
    "        b = 0\n",
    "\n",
    "    # Store w and b in svm_model\n",
    "    svm_model = {'w': w, 'b': b}\n",
    "\n",
    "    # Predict on validation and test sets using svm_predict_primal\n",
    "    val_accuracy = svm_predict_primal(val_data, val_labels, svm_model)\n",
    "    test_accuracy = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_primal_from_dual(alpha, data_train, label_train, regularisation_para_C):\n",
    "    \"\"\"\n",
    "    Compute the primal SVM solution (w*, b*) from the dual solution alpha*.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: Dual solution (N,)\n",
    "    - data_train: Training data matrix (N x D)\n",
    "    - label_train: Training labels (N,)\n",
    "    - regularisation_para_C: Regularization parameter C\n",
    "\n",
    "    Returns:\n",
    "    - w: Weight vector (D,)\n",
    "    - b: Bias scalar\n",
    "    \"\"\"\n",
    "    # Compute w* from alpha*\n",
    "    w = np.sum((alpha * label_train)[:, None] * data_train, axis=0)\n",
    "\n",
    "    # Compute b* using a support vector\n",
    "    # Find a support vector index (any example where 0 < alpha < C/N)\n",
    "    support_vector_indices = np.where((alpha > 1e-5) & (alpha < (regularisation_para_C / data_train.shape[0])))[0]\n",
    "    if len(support_vector_indices) > 0:\n",
    "        sv_index = support_vector_indices[0]\n",
    "        b = label_train[sv_index] - np.dot(w, data_train[sv_index])\n",
    "    else:\n",
    "        b = 0\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primal from Dual:\tsum of w:  -0.14481804997142345\n",
      "Primal from Dual:\tb:  1.7788072646376278\n",
      "sum of w:  -0.1452156803361282\n",
      "b:  1.779813717087077\n",
      "Validation Accuracy: 96.96%\n",
      "Test Accuracy: 96.80%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'svm_train_dual_with_regularization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m#calculate w abd b from primal form and compare with dual form\u001b[39;00m\n\u001b[0;32m      8\u001b[0m primal_svm_driver()\n\u001b[1;32m----> 9\u001b[0m dual_svm_driver()\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mdual_svm_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m train_data, train_labels, _, _, _, _ \u001b[39m=\u001b[39m load_and_split_data()\n\u001b[0;32m      5\u001b[0m \u001b[39m# # Convert labels from {0, 1} to {-1, 1}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# train_labels = 2 * train_labels - 1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[39m# Train SVM in dual form\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m alpha_values \u001b[39m=\u001b[39m svm_train_dual_with_regularization(train_data, train_labels, \u001b[39m100\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Compute the weight vector w\u001b[39;00m\n\u001b[0;32m     12\u001b[0m w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((alpha_values \u001b[39m*\u001b[39m train_labels)[:, \u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m train_data, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm_train_dual_with_regularization' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    alpha = svm_train_dual(train_data, train_labels, 100)\n",
    "    w, b = compute_primal_from_dual(alpha, train_data, train_labels, 100)\n",
    "    print(\"Primal from Dual:\\tsum of w: \", np.sum(w))\n",
    "    print(\"Primal from Dual:\\tb: \", b)\n",
    "    #calculate w abd b from primal form and compare with dual form\n",
    "    primal_svm_driver()\n",
    "    dual_svm_driver()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
