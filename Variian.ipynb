{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(train_path=\"train.csv\", test_path=\"test.csv\"):\n",
    "    \"\"\"\n",
    "    Load data from CSV files and split into training, validation, and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_path: Path to the training CSV file.\n",
    "    - test_path: Path to the testing CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    - train_data, train_labels: Training data and labels.\n",
    "    - val_data, val_labels: Validation data and labels.\n",
    "    - test_data, test_labels: Test data and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load train.csv and split\n",
    "    train_df = pd.read_csv(train_path, header=None)\n",
    "\n",
    "    train_data = train_df.iloc[:4000, 1:].values\n",
    "    train_labels = train_df.iloc[:4000, 0].values\n",
    "\n",
    "    # print(\"The first 10 labels in the training set are: \", train_labels[:10])\n",
    "    # print(\"The first 10 features in the training set are: \", train_data[:10])    \n",
    "    \n",
    "    val_data = train_df.iloc[4000:, 1:].values\n",
    "    val_labels = train_df.iloc[4000:, 0].values\n",
    "    \n",
    "    # Load test.csv\n",
    "    test_df = pd.read_csv(test_path, header=None)\n",
    "    test_data = test_df.iloc[:, 1:].values\n",
    "    test_labels = test_df.iloc[:, 0].values\n",
    "\n",
    "    test_labels = test_labels * 2 - 1\n",
    "    val_labels = val_labels * 2 - 1\n",
    "    train_labels = train_labels * 2 - 1\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "# Load data\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_and_split_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, w, b):\n",
    "    \"\"\"\n",
    "    Predict labels for given data using weight vector w and bias b.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Data matrix.\n",
    "    - w: Weight vector.\n",
    "    - b: Bias scalar.\n",
    "    \n",
    "    Returns:\n",
    "    - labels: Predicted labels.\n",
    "    \"\"\"\n",
    "    return np.sign(data @ w + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_primal(data_train, label_train, regularisation_para_C):\n",
    "    \"\"\"\n",
    "    Train a linear SVM in the primal form using cvxpy.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_train: Training data matrix of shape (N, d)\n",
    "    - label_train: Training labels vector of shape (N, )\n",
    "    - regularisation_para_C: Regularization parameter\n",
    "    \n",
    "    Returns:\n",
    "    - w: Weight vector of shape (d, )\n",
    "    - b: Bias (scalar)\n",
    "    \"\"\"\n",
    "    \n",
    "    N, d = data_train.shape\n",
    "    w = cp.Variable(d)\n",
    "    b = cp.Variable()\n",
    "    xi = cp.Variable(N)\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(0.5 * cp.norm(w,2)**2 + (regularisation_para_C/N) * cp.sum(xi))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [cp.multiply(label_train, data_train @ w + b) >= 1 - xi, xi >= 0]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return w.value, b.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix K is NOT positive semidefinite. Minimum eigenvalue: -2.726553868824963e-11\n"
     ]
    }
   ],
   "source": [
    "def is_positive_semidefinite(K):\n",
    "    \"\"\"\n",
    "    Check if matrix K is positive semidefinite.\n",
    "    \n",
    "    Parameters:\n",
    "    - K: Square matrix\n",
    "    \n",
    "    Returns:\n",
    "    - True if K is positive semidefinite, False otherwise.\n",
    "    \"\"\"\n",
    "    eigenvalues = np.linalg.eigvalsh(K)\n",
    "    return np.all(eigenvalues >= 0)\n",
    "\n",
    "# Construct the kernel (gram matrix) for the training data\n",
    "K = np.outer(train_labels, train_labels) * (train_data @ train_data.T)\n",
    "\n",
    "# Check if K is positive semidefinite\n",
    "if is_positive_semidefinite(K):\n",
    "    print(\"Matrix K is positive semidefinite.\")\n",
    "else:\n",
    "    print(\"Matrix K is NOT positive semidefinite. Minimum eigenvalue:\", np.min(np.linalg.eigvalsh(K)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    regularization_term = 1e-5\n",
    "    N, _ = data_train.shape\n",
    "    alpha = cp.Variable(N)\n",
    "    \n",
    "    # Construct the kernel (gram matrix) with regularization\n",
    "    K = np.outer(label_train, label_train) * (data_train @ data_train.T)\n",
    "    K += np.eye(N) * regularization_term\n",
    "    \n",
    "    # Explicitly compute the quadratic term for the objective using quad_form\n",
    "    quadratic_term = 0.5 * cp.quad_form(alpha, K)\n",
    "    \n",
    "    # Objective\n",
    "    objective = cp.Minimize(-1 * cp.sum(alpha) + quadratic_term)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(cp.multiply(alpha, label_train)) == 0,\n",
    "        alpha >= 0,\n",
    "        alpha <= regularisation_para_C / N\n",
    "    ]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return alpha.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict_primal(data, labels, svm_model):\n",
    "    \"\"\"\n",
    "    Predict using the primal SVM model and return accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Data matrix (N x D)\n",
    "    - labels: Ground truth labels (N,)\n",
    "    - svm_model: Trained SVM model with 'w' and 'b' as keys\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy of predictions\n",
    "    \"\"\"\n",
    "    # Extract w and b from the model\n",
    "    w = svm_model['w']\n",
    "    b = svm_model['b']\n",
    "\n",
    "    # Predict\n",
    "    preds = np.sign(np.dot(data, w) + b)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(preds == labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_svm_driver():\n",
    "    # Load data\n",
    "    train_data, train_labels, val_data, val_labels, test_data, test_labels = load_and_split_data()\n",
    "    \n",
    "    # Train SVM\n",
    "    w, b = svm_train_primal(train_data, train_labels, 100)\n",
    "\n",
    "    # Store w and b in svm_model\n",
    "    svm_model = {'w': w, 'b': b}\n",
    "    \n",
    "    # Predict on validation and test sets using svm_predict_primal\n",
    "    val_accuracy = svm_predict_primal(val_data, val_labels, svm_model)\n",
    "    test_accuracy = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return svm_model, val_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_svm_driver(train_data, train_labels, C):\n",
    "        # Load the data (assuming load_and_split_data is defined)\n",
    "    # train_data, train_labels, _, _, _, _ = load_and_split_data()\n",
    "\n",
    "    # # Convert labels from {0, 1} to {-1, 1}\n",
    "    # train_labels = 2 * train_labels - 1\n",
    "\n",
    "    # Train SVM in dual form\n",
    "    alpha_values = svm_train_dual(train_data, train_labels, C)\n",
    "\n",
    "    # # Compute the weight vector w\n",
    "    # w = np.sum((alpha_values * train_labels)[:, None] * train_data, axis=0)\n",
    "\n",
    "    # # Compute the bias b using a support vector (any example where 0 < alpha < C/N can be a support vector)\n",
    "    # support_vector_indices = np.where((alpha_values > 1e-5) & (alpha_values < (100/train_data.shape[0])))[0]\n",
    "    # if len(support_vector_indices) > 0:\n",
    "    #     sv_index = support_vector_indices[0]\n",
    "    #     b = train_labels[sv_index] - np.dot(w, train_data[sv_index])\n",
    "    # else:\n",
    "    #     b = 0\n",
    "\n",
    "    # Store w and b in svm_model\n",
    "    svm_model = {'alpha_values': alpha_values}\n",
    "\n",
    "    # Predict on validation and test sets using svm_predict_primal\n",
    "    val_accuracy = svm_predict_primal(val_data, val_labels, svm_model)\n",
    "    test_accuracy = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return svm_model, val_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_primal_from_dual(alpha, data_train, label_train, regularisation_para_C):\n",
    "    \"\"\"\n",
    "    Compute the primal SVM solution (w*, b*) from the dual solution alpha*.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: Dual solution (N,)\n",
    "    - data_train: Training data matrix (N x D)\n",
    "    - label_train: Training labels (N,)\n",
    "    - regularisation_para_C: Regularization parameter C\n",
    "\n",
    "    Returns:\n",
    "    - w: Weight vector (D,)\n",
    "    - b: Bias scalar\n",
    "    \"\"\"\n",
    "    # Compute w* from alpha*\n",
    "    w = np.sum((alpha * label_train)[:, None] * data_train, axis=0)\n",
    "\n",
    "    # Compute b* using a support vector\n",
    "    # Find a support vector index (any example where 0 < alpha < C/N)\n",
    "    support_vector_indices = np.where((alpha > 1e-5) & (alpha < (regularisation_para_C / data_train.shape[0])))[0]\n",
    "    if len(support_vector_indices) > 0:\n",
    "        sv_index = support_vector_indices[0]\n",
    "        b = label_train[sv_index] - np.dot(w, data_train[sv_index])\n",
    "    else:\n",
    "        b = 0\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'w'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Run the main function\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     alpha, dual_val_accuracy, dual_test_accuracy \u001b[39m=\u001b[39m dual_svm_driver(train_data, train_labels, \u001b[39m100\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     w, b \u001b[39m=\u001b[39m compute_primal_from_dual(alpha[\u001b[39m'\u001b[39m\u001b[39malpha_values\u001b[39m\u001b[39m'\u001b[39m], train_data, train_labels, \u001b[39m100\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrimal numebrs from Dual:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39msum of w: \u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39msum(w))\n",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m, in \u001b[0;36mdual_svm_driver\u001b[1;34m(train_data, train_labels, C)\u001b[0m\n\u001b[0;32m     23\u001b[0m svm_model \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39malpha_values\u001b[39m\u001b[39m'\u001b[39m: alpha_values}\n\u001b[0;32m     25\u001b[0m \u001b[39m# Predict on validation and test sets using svm_predict_primal\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m val_accuracy \u001b[39m=\u001b[39m svm_predict_primal(val_data, val_labels, svm_model)\n\u001b[0;32m     27\u001b[0m test_accuracy \u001b[39m=\u001b[39m svm_predict_primal(test_data, test_labels, svm_model)\n\u001b[0;32m     29\u001b[0m \u001b[39m# Print results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m, in \u001b[0;36msvm_predict_primal\u001b[1;34m(data, labels, svm_model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mPredict using the primal SVM model and return accuracy.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m- Accuracy of predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Extract w and b from the model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m w \u001b[39m=\u001b[39m svm_model[\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     15\u001b[0m b \u001b[39m=\u001b[39m svm_model[\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39m# Predict\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'w'"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    alpha, dual_val_accuracy, dual_test_accuracy = dual_svm_driver(train_data, train_labels, 100)\n",
    "    w, b = compute_primal_from_dual(alpha['alpha_values'], train_data, train_labels, 100)\n",
    "    print(\"Primal numebrs from Dual:\\tsum of w: \", np.sum(w))\n",
    "    print(\"Primal numbers from Dual:\\tb: \", b)\n",
    "    \n",
    "    #calculate w abd b from primal form and compare with dual form\n",
    "    svm_model, primal_val_accuracy, dual_test_accuracy = primal_svm_driver()\n",
    "    print(\"Primal straight:\\tsum of w: \", np.sum(svm_model['w']))\n",
    "    print(\"Primal straight:\\tb: \", svm_model['b'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
