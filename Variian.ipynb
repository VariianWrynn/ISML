{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(train_path=\"train.csv\", test_path=\"test.csv\"):\n",
    "    \"\"\"\n",
    "    Load data from CSV files and split into training, validation, and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_path: Path to the training CSV file.\n",
    "    - test_path: Path to the testing CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    - train_data, train_labels: Training data and labels.\n",
    "    - val_data, val_labels: Validation data and labels.\n",
    "    - test_data, test_labels: Test data and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load train.csv and split\n",
    "    train_df = pd.read_csv(train_path, header=None)\n",
    "\n",
    "    train_data = train_df.iloc[:4000, 1:].values\n",
    "    train_labels = train_df.iloc[:4000, 0].values\n",
    "\n",
    "    # print(\"The first 10 labels in the training set are: \", train_labels[:10])\n",
    "    # print(\"The first 10 features in the training set are: \", train_data[:10])    \n",
    "    \n",
    "    val_data = train_df.iloc[4000:, 1:].values\n",
    "    val_labels = train_df.iloc[4000:, 0].values\n",
    "    \n",
    "    # Load test.csv\n",
    "    test_df = pd.read_csv(test_path, header=None)\n",
    "    test_data = test_df.iloc[:, 1:].values\n",
    "    test_labels = test_df.iloc[:, 0].values\n",
    "\n",
    "    test_labels = test_labels * 2 - 1\n",
    "    val_labels = val_labels * 2 - 1\n",
    "    train_labels = train_labels * 2 - 1\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "# Load data\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = load_and_split_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_primal(data_train, label_train, regularisation_para_C):    \n",
    "    N, d = data_train.shape\n",
    "    w = cp.Variable(d)\n",
    "    b = cp.Variable()\n",
    "    xi = cp.Variable(N)\n",
    "    \n",
    "    # Objective function\n",
    "    objective = cp.Minimize(0.5 * cp.norm(w,2)**2 + (regularisation_para_C/N) * cp.sum(xi))\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [cp.multiply(label_train, data_train @ w + b) >= 1 - xi, xi >= 0]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "    svm_model = {'w': w.value, 'b': b.value}\n",
    "    \n",
    "    return svm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict_primal(data_test, label_test, svm_model):\n",
    "    # Extract w and b from the model\n",
    "    w = svm_model['w']\n",
    "    b = svm_model['b']\n",
    "\n",
    "    # Predict\n",
    "    preds = np.sign(np.dot(data_test, w) + b)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    test_accuracy = np.mean(preds == label_test)\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 1.779813717087077\n",
      "sum of w: -0.1452156803361282\n",
      "Test Accuracy: 96.80%\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm_train_primal(train_data, train_labels, 100)\n",
    "#print b and sum of w\n",
    "print(f\"b: {svm_model['b']}\")\n",
    "print(f\"sum of w: {np.sum(svm_model['w'])}\")\n",
    "#test for the accuraccy\n",
    "test_accuracy = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    # regularization_term = 0\n",
    "    N,_ = data_train.shape\n",
    "    alpha = cp.Variable((N,1))\n",
    "\n",
    "    # Reshape label_train to be a column vector\n",
    "    label_train = label_train.reshape(-1, 1)\n",
    "    mult = label_train * data_train\n",
    "\n",
    "    mult_transpose = mult.T\n",
    "\n",
    "    # Construct the kernel (gram matrix) with regularization\\\n",
    "    K = cp.sum_squares(mult_transpose @ alpha)\n",
    "    \n",
    "    # Objective\n",
    "    objective = cp.Minimize(-1 * cp.sum(alpha) + K)\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(cp.multiply(alpha, label_train)) == 0,\n",
    "        alpha >= 0,\n",
    "        alpha <= regularisation_para_C / N\n",
    "    ]\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return alpha.value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_primal_from_dual(alpha, data_train, label_train, regularisation_para_C):\n",
    "    \"\"\"\n",
    "    Compute the primal SVM solution (w*, b*) from the dual solution alpha*.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: Dual solution (N,)\n",
    "    - data_train: Training data matrix (N x D)\n",
    "    - label_train: Training labels (N,)\n",
    "    - regularisation_para_C: Regularization parameter C\n",
    "\n",
    "    Returns:\n",
    "    - w: Weight vector (D,)\n",
    "    - b: Bias scalar\n",
    "    \"\"\"\n",
    "    # Compute w* from alpha*\n",
    "    w = np.sum((alpha * label_train)[:, None] * data_train, axis=0)\n",
    "\n",
    "    # Compute b* using a support vector\n",
    "    # Find a support vector index (any example where 0 < alpha < C/N)\n",
    "    support_vector_indices = np.where((alpha > 1e-5) & (alpha < (regularisation_para_C / data_train.shape[0])))[0]\n",
    "    if len(support_vector_indices) > 0:\n",
    "        sv_index = support_vector_indices[0]\n",
    "        b = label_train[sv_index] - np.dot(w, data_train[sv_index])\n",
    "    else:\n",
    "        b = 0\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_support_vectors_from_primal(data_train, label_train, svm_model):\n",
    "    \"\"\"\n",
    "    Find the support vectors based on the primal SVM model.\n",
    "\n",
    "    Parameters:\n",
    "    - data_train: Training data matrix (N x D)\n",
    "    - label_train: Training labels (N,)\n",
    "    - svm_model: Trained SVM model with 'w' and 'b' as keys\n",
    "\n",
    "    Returns:\n",
    "    - support_vectors: Matrix of support vectors (S x D)\n",
    "    - support_vector_labels: Labels of the support vectors (S,)\n",
    "    - support_vector_indices: Indices of the support vectors in the training data\n",
    "    \"\"\"\n",
    "    # Extract w and b from the model\n",
    "    w = svm_model['w']\n",
    "    b = svm_model['b']\n",
    "\n",
    "    # Compute decision values\n",
    "    decision_values = label_train * (np.dot(data_train, w) + b)\n",
    "    \n",
    "    # Identify support vectors\n",
    "    support_vector_indices = np.where(decision_values <= 1)[0]\n",
    "    support_vectors = data_train[support_vector_indices]\n",
    "    support_vector_labels = label_train[support_vector_indices]\n",
    "\n",
    "    return support_vectors, support_vector_labels, support_vector_indices\n",
    "\n",
    "# Test the function using the provided SVM model (assuming it's available in the notebook)\n",
    "# This step assumes that the variables train_data, train_labels, and svm_model are already loaded.\n",
    "# svm_model = {\"w\": w, \"b\": b}\n",
    "# support_vectors, support_vector_labels, support_vector_indices = find_support_vectors_from_primal(train_data, train_labels, svm_model)\n",
    "# len(support_vector_indices)  # This will display the number of support vectors found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_support_vectors_from_dual(data_train, label_train, alpha_values, threshold=1e-5):\n",
    "    \"\"\"\n",
    "    Find the support vectors based on the dual SVM solution.\n",
    "\n",
    "    Parameters:\n",
    "    - data_train: Training data matrix (N x D)\n",
    "    - label_train: Training labels (N,)\n",
    "    - alpha_values: Values of the Lagrange multipliers from the dual solution (N,)\n",
    "    - threshold: Threshold for considering a data point as a support vector\n",
    "\n",
    "    Returns:\n",
    "    - support_vectors: Matrix of support vectors (S x D)\n",
    "    - support_vector_labels: Labels of the support vectors (S,)\n",
    "    - support_vector_indices: Indices of the support vectors in the training data\n",
    "    - support_vector_alphas: Values of the Lagrange multipliers for the support vectors\n",
    "    \"\"\"\n",
    "    # Identify support vectors based on alpha values\n",
    "    support_vector_indices = np.where(alpha_values > threshold)[0]\n",
    "    support_vectors = data_train[support_vector_indices]\n",
    "    support_vector_labels = label_train[support_vector_indices]\n",
    "    support_vector_alphas = alpha_values[support_vector_indices]\n",
    "\n",
    "    return support_vectors, support_vector_labels, support_vector_indices, support_vector_alphas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 (BEST C IS 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_C(train_data, train_labels, val_data, val_labels):\n",
    "    \"\"\"\n",
    "    Choose the best value of C using the validation set.\n",
    "\n",
    "    Parameters:\n",
    "    - train_data: Training data matrix\n",
    "    - train_labels: Training labels\n",
    "    - val_data: Validation data matrix\n",
    "    - val_labels: Validation labels\n",
    "\n",
    "    Returns:\n",
    "    - best_C: Optimal value of C\n",
    "    - best_accuracy: Accuracy on the validation set using the best C\n",
    "    \"\"\"\n",
    "    C_values = [2**i for i in range(-2, 11)]\n",
    "    best_accuracy = -0.1\n",
    "    best_C = None\n",
    "    \n",
    "    for C in C_values:\n",
    "        # print(\"Training for C={}\".format(C))\n",
    "        # Train SVM using the current value of C\n",
    "        svm_model = svm_train_primal(train_data, train_labels, C)\n",
    "        # print(svm_model)\n",
    "\n",
    "        val_preds = svm_predict_primal(val_data, val_labels, svm_model)\n",
    "        # print(f\"PREDICTIONS: {val_preds[:30]}\")\n",
    "        \n",
    "        # Compute accuracy on the validation set\n",
    "        accuracy = np.mean(val_preds == val_labels)\n",
    "        # print(\"Accuracy for C={}: {}\".format(C, accuracy))\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            # print(\"Found better value of C: {} with accuracy: {}\".format(C, accuracy))\n",
    "            best_accuracy = accuracy\n",
    "            best_C = C\n",
    "            \n",
    "    return best_C, best_accuracy\n",
    "\n",
    "# Using the above function\n",
    "best_C, best_val_accuracy = select_best_C(train_data, train_labels, val_data, val_labels)\n",
    "print(f\"Best C: {best_C}, Validation Accuracy: {best_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Train the SVM using the best C and report test accuracy\n",
    "svm_model = svm_train_primal(train_data, train_labels, best_C)\n",
    "\n",
    "test_preds = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "test_accuracy = np.mean(test_preds == test_labels)\n",
    "print(f\"Test Accuracy using best C: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "def sklearn_svm():\n",
    "\n",
    "    #CREAT A SVC model, with C= 4\n",
    "    svc_model = Pipeline([('svc', SVC(C=4, kernel='linear'))])\n",
    "\n",
    "    #fit the model using the pipeline\n",
    "    svc_model.fit(train_data, train_labels)\n",
    "\n",
    "    #predict the model\n",
    "    svc_preds = svc_model.predict(test_data)\n",
    "\n",
    "    #compute the accuracy\n",
    "    svc_accuracy = np.mean(svc_preds == test_labels)\n",
    "    print(f\"Test Accuracy using best C: {svc_accuracy * 100:.2f}%\")\n",
    "    return svc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the above function\n",
    "best_C, best_val_accuracy = select_best_C(train_data, train_labels, val_data, val_labels)\n",
    "print(f\"Best C: {best_C}, Validation Accuracy: {best_val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Train the SVM using the best C and report test accuracy\n",
    "svm_model = svm_train_primal(train_data, train_labels, best_C)\n",
    "\n",
    "test_preds = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "test_accuracy = np.mean(test_preds == test_labels)\n",
    "print(f\"Test Accuracy using best C: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual: sum of alpha:  6.469633954792531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\think\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\cvxpy\\problems\\problem.py:1387: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "alpha = svm_train_dual(train_data, train_labels, 100)\n",
    "print(\"Dual: sum of alpha: \", np.sum(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = compute_primal_from_dual(alpha, train_data, train_labels, 100)\n",
    "print(\"Primal from Dual:\\tsum of w: \", np.sum(w))\n",
    "print(\"Primal from Dual:\\tb: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm_train_primal(train_data, train_labels, 100)\n",
    "print(\"Primal straight away:\\tsum of w: \", np.sum(svm_model['w']))\n",
    "print(\"Primal straight away:\\tb: \", svm_model['b'])\n",
    "#test for the accuraccy\n",
    "test_preds = svm_predict_primal(test_data, test_labels, svm_model)\n",
    "print(\"Primal straight away:\\ttest accuracy: \", np.mean(test_preds == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vectors, support_vector_labels, support_vector_indices = find_support_vectors_from_primal(train_data, train_labels, svm_model)\n",
    "print(\"Number of support vectors: \", len(support_vector_indices))\n",
    "print(\"Support vector indices: \", support_vector_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vectors, support_vector_labels, support_vector_indices, support_vector_alphas = find_support_vectors_from_dual(train_data, train_labels, alpha)\n",
    "print(\"Number of support vectors: \", len(support_vector_indices))\n",
    "print(\"Support vector indices: \", support_vector_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
